// NOTE: Assertions have been autogenerated by utils/update_cc_test_checks.py
// RUN: %clang_cc1 -triple aarch64-none-elf -target-feature +morello -target-feature +c64 -disable-O0-optnone -target-abi purecap %s -S -emit-llvm -o - | opt -sroa -S | FileCheck %s
struct S1 {
  void *a;
  void *b;
};

void bar(struct S1 arg);

// CHECK-LABEL: @foo(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[LIST:%.*]] = alloca i8 addrspace(200)*, align 16, addrspace(200)
// CHECK-NEXT:    [[LIST1:%.*]] = bitcast i8 addrspace(200)* addrspace(200)* [[LIST]] to i8 addrspace(200)*
// CHECK-NEXT:    call void @llvm.va_start.p200i8(i8 addrspace(200)* [[LIST1]])
// CHECK-NEXT:    [[STACK:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[LIST]], align 16
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast i8 addrspace(200)* [[STACK]] to [[STRUCT_S1:%.*]] addrspace(200)* addrspace(200)*
// CHECK-NEXT:    [[NEW_STACK:%.*]] = getelementptr inbounds i8, i8 addrspace(200)* [[STACK]], i64 16
// CHECK-NEXT:    store i8 addrspace(200)* [[NEW_STACK]], i8 addrspace(200)* addrspace(200)* [[LIST]], align 16
// CHECK-NEXT:    [[VAARG_ADDR:%.*]] = load [[STRUCT_S1]] addrspace(200)*, [[STRUCT_S1]] addrspace(200)* addrspace(200)* [[TMP0]], align 16
// CHECK-NEXT:    [[ARG_SROA_0_0__SROA_IDX:%.*]] = getelementptr inbounds [[STRUCT_S1]], [[STRUCT_S1]] addrspace(200)* [[VAARG_ADDR]], i64 0, i32 0
// CHECK-NEXT:    [[ARG_SROA_0_0_COPYLOAD:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[ARG_SROA_0_0__SROA_IDX]], align 16
// CHECK-NEXT:    [[ARG_SROA_2_0__SROA_IDX1:%.*]] = getelementptr inbounds [[STRUCT_S1]], [[STRUCT_S1]] addrspace(200)* [[VAARG_ADDR]], i64 0, i32 1
// CHECK-NEXT:    [[ARG_SROA_2_0_COPYLOAD:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[ARG_SROA_2_0__SROA_IDX1]], align 16
// CHECK-NEXT:    [[DOTFCA_0_INSERT:%.*]] = insertvalue { i8 addrspace(200)*, i8 addrspace(200)* } poison, i8 addrspace(200)* [[ARG_SROA_0_0_COPYLOAD]], 0
// CHECK-NEXT:    [[DOTFCA_1_INSERT:%.*]] = insertvalue { i8 addrspace(200)*, i8 addrspace(200)* } [[DOTFCA_0_INSERT]], i8 addrspace(200)* [[ARG_SROA_2_0_COPYLOAD]], 1
// CHECK-NEXT:    call void @bar({ i8 addrspace(200)*, i8 addrspace(200)* } [[DOTFCA_1_INSERT]])
// CHECK-NEXT:    [[LIST2:%.*]] = bitcast i8 addrspace(200)* addrspace(200)* [[LIST]] to i8 addrspace(200)*
// CHECK-NEXT:    call void @llvm.va_end.p200i8(i8 addrspace(200)* [[LIST2]])
// CHECK-NEXT:    ret void
//
void foo(int i, ...) {
  __builtin_va_list list;
  __builtin_va_start(list, i);
  struct S1 arg = __builtin_va_arg(list, struct S1);
  bar(arg);
  __builtin_va_end(list);
}

struct S2 {
  long x1;
  long x2;
  long x3;
  long x4;
};

void bat(struct S2 arg);

// CHECK-LABEL: @baz(
// CHECK-NEXT:  entry:
// CHECK-NEXT:    [[LIST:%.*]] = alloca i8 addrspace(200)*, align 16, addrspace(200)
// CHECK-NEXT:    [[ARG:%.*]] = alloca [[STRUCT_S2:%.*]], align 8, addrspace(200)
// CHECK-NEXT:    [[BYVAL_TEMP:%.*]] = alloca [[STRUCT_S2]], align 8, addrspace(200)
// CHECK-NEXT:    [[LIST1:%.*]] = bitcast i8 addrspace(200)* addrspace(200)* [[LIST]] to i8 addrspace(200)*
// CHECK-NEXT:    call void @llvm.va_start.p200i8(i8 addrspace(200)* [[LIST1]])
// CHECK-NEXT:    [[STACK:%.*]] = load i8 addrspace(200)*, i8 addrspace(200)* addrspace(200)* [[LIST]], align 16
// CHECK-NEXT:    [[TMP0:%.*]] = bitcast i8 addrspace(200)* [[STACK]] to [[STRUCT_S2]] addrspace(200)* addrspace(200)*
// CHECK-NEXT:    [[NEW_STACK:%.*]] = getelementptr inbounds i8, i8 addrspace(200)* [[STACK]], i64 16
// CHECK-NEXT:    store i8 addrspace(200)* [[NEW_STACK]], i8 addrspace(200)* addrspace(200)* [[LIST]], align 16
// CHECK-NEXT:    [[VAARG_ADDR:%.*]] = load [[STRUCT_S2]] addrspace(200)*, [[STRUCT_S2]] addrspace(200)* addrspace(200)* [[TMP0]], align 16
// CHECK-NEXT:    [[TMP1:%.*]] = bitcast [[STRUCT_S2]] addrspace(200)* [[ARG]] to i8 addrspace(200)*
// CHECK-NEXT:    [[TMP2:%.*]] = bitcast [[STRUCT_S2]] addrspace(200)* [[VAARG_ADDR]] to i8 addrspace(200)*
// CHECK-NEXT:    call void @llvm.memcpy.p200i8.p200i8.i64(i8 addrspace(200)* align 8 [[TMP1]], i8 addrspace(200)* align 8 [[TMP2]], i64 32, i1 false)
// CHECK-NEXT:    [[TMP3:%.*]] = bitcast [[STRUCT_S2]] addrspace(200)* [[BYVAL_TEMP]] to i8 addrspace(200)*
// CHECK-NEXT:    [[TMP4:%.*]] = bitcast [[STRUCT_S2]] addrspace(200)* [[ARG]] to i8 addrspace(200)*
// CHECK-NEXT:    call void @llvm.memcpy.p200i8.p200i8.i64(i8 addrspace(200)* align 8 [[TMP3]], i8 addrspace(200)* align 8 [[TMP4]], i64 32, i1 false)
// CHECK-NEXT:    call void @bat([[STRUCT_S2]] addrspace(200)* noundef [[BYVAL_TEMP]])
// CHECK-NEXT:    [[LIST2:%.*]] = bitcast i8 addrspace(200)* addrspace(200)* [[LIST]] to i8 addrspace(200)*
// CHECK-NEXT:    call void @llvm.va_end.p200i8(i8 addrspace(200)* [[LIST2]])
// CHECK-NEXT:    ret void
//
void baz(int i, ...) {
  __builtin_va_list list;
  __builtin_va_start(list, i);
  struct S2 arg = __builtin_va_arg(list, struct S2);
  bat(arg);
  __builtin_va_end(list);
}
