; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes --force-update
; DO NOT EDIT -- This file was generated from test/CodeGen/CHERI-Generic/Inputs/machinelicm-hoist-csetbounds.ll
; Previously LLVM would hoist CSetBounds instructions out of if conditions/loops
; even if the source pointer could be NULL. On MIPS and RISC-V this results in a
; tag violation so we must ensure that the CSetBounds happens after the NULL check.

; Note: Opt correctly hoists the condition+csetbounds into a preheader, and LLC
; used to unconditionally hoist the csetbounds.
; RUN: opt -mtriple=aarch64 --relocation-model=pic -target-abi purecap -mattr=+morello,+c64 -O3 -S < %s | FileCheck %s --check-prefix=HOIST-OPT
; RUN: llc -mtriple=aarch64 --relocation-model=pic -target-abi purecap -mattr=+morello,+c64 -O3 < %s | FileCheck %s

; Generated from the following C code (with subobject bounds):
; struct foo {
;     int src;
;     int dst;
; };
;
; void call(int* src, int* dst);
;
; void hoist_csetbounds(int cond, struct foo* f) {
;     for (int i = 0; i < 100; i++) {
;         if (f) {
;             call(&f->src, &f->dst);
;         }
;     }
; }

%struct.foo = type { i32, i32 }
declare dso_local void @call(i32 addrspace(200)*, i32 addrspace(200)*) local_unnamed_addr addrspace(200) nounwind
declare i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)*, i64) addrspace(200) nounwind readnone willreturn

define dso_local void @hoist_csetbounds(i32 signext %cond, %struct.foo addrspace(200)* %f) local_unnamed_addr addrspace(200) nounwind {
; CHECK-LABEL: hoist_csetbounds:
; CHECK:       .Lhoist_csetbounds$local:
; CHECK-NEXT:  .Lfunc_begin0:
; CHECK-NEXT:  // %bb.0: // %entry
; CHECK-NEXT:    str c30, [csp, #-80]! // 16-byte Folded Spill
; CHECK-NEXT:    add c0, c1, #4 // =4
; CHECK-NEXT:    stp c22, c21, [csp, #16] // 32-byte Folded Spill
; CHECK-NEXT:    stp c20, c19, [csp, #48] // 32-byte Folded Spill
; CHECK-NEXT:    mov c19, c1
; CHECK-NEXT:    mov w22, #-1
; CHECK-NEXT:    scbnds c20, c1, #4 // =4
; CHECK-NEXT:    scbnds c21, c0, #4 // =4
; CHECK-NEXT:    b .LBB0_2
; CHECK-NEXT:  .LBB0_1: // %for.inc
; CHECK-NEXT:    // in Loop: Header=BB0_2 Depth=1
; CHECK-NEXT:    add w22, w22, #1 // =1
; CHECK-NEXT:    cmp w22, #99 // =99
; CHECK-NEXT:    b.hs .LBB0_4
; CHECK-NEXT:  .LBB0_2: // %for.body
; CHECK-NEXT:    // =>This Inner Loop Header: Depth=1
; CHECK-NEXT:    cbz x19, .LBB0_1
; CHECK-NEXT:  // %bb.3: // %if.then
; CHECK-NEXT:    // in Loop: Header=BB0_2 Depth=1
; CHECK-NEXT:    mov c0, c20
; CHECK-NEXT:    mov c1, c21
; CHECK-NEXT:    bl call
; CHECK-NEXT:    b .LBB0_1
; CHECK-NEXT:  .LBB0_4: // %for.cond.cleanup
; CHECK-NEXT:    ldp c20, c19, [csp, #48] // 32-byte Folded Reload
; CHECK-NEXT:    ldp c22, c21, [csp, #16] // 32-byte Folded Reload
; CHECK-NEXT:    ldr c30, [csp], #80 // 16-byte Folded Reload
; CHECK-NEXT:    ret c30
; HOIST-OPT-LABEL: define {{[^@]+}}@hoist_csetbounds
; HOIST-OPT-SAME: (i32 signext [[COND:%.*]], [[STRUCT_FOO:%.*]] addrspace(200)* [[F:%.*]]) local_unnamed_addr addrspace(200) [[ATTR0:#.*]] {
; HOIST-OPT-NEXT:  entry:
; HOIST-OPT-NEXT:    [[TOBOOL:%.*]] = icmp eq [[STRUCT_FOO]] addrspace(200)* [[F]], null
; HOIST-OPT-NEXT:    br i1 [[TOBOOL]], label [[FOR_COND_CLEANUP:%.*]], label [[FOR_BODY_PREHEADER:%.*]]
; HOIST-OPT:       for.body.preheader:
; HOIST-OPT-NEXT:    [[DST:%.*]] = getelementptr inbounds [[STRUCT_FOO]], [[STRUCT_FOO]] addrspace(200)* [[F]], i64 0, i32 1
; HOIST-OPT-NEXT:    [[TMP0:%.*]] = bitcast i32 addrspace(200)* [[DST]] to i8 addrspace(200)*
; HOIST-OPT-NEXT:    [[TMP1:%.*]] = bitcast [[STRUCT_FOO]] addrspace(200)* [[F]] to i8 addrspace(200)*
; HOIST-OPT-NEXT:    [[TMP2:%.*]] = tail call addrspace(200) i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP1]], i64 4)
; HOIST-OPT-NEXT:    [[ADDRESS_WITH_BOUNDS:%.*]] = bitcast i8 addrspace(200)* [[TMP2]] to i32 addrspace(200)*
; HOIST-OPT-NEXT:    [[TMP3:%.*]] = tail call addrspace(200) i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull [[TMP0]], i64 4)
; HOIST-OPT-NEXT:    [[ADDRESS_WITH_BOUNDS1:%.*]] = bitcast i8 addrspace(200)* [[TMP3]] to i32 addrspace(200)*
; HOIST-OPT-NEXT:    br label [[FOR_BODY:%.*]]
; HOIST-OPT:       for.cond.cleanup:
; HOIST-OPT-NEXT:    ret void
; HOIST-OPT:       for.body:
; HOIST-OPT-NEXT:    [[I_06:%.*]] = phi i32 [ [[INC:%.*]], [[FOR_BODY]] ], [ 0, [[FOR_BODY_PREHEADER]] ]
; HOIST-OPT-NEXT:    tail call addrspace(200) void @call(i32 addrspace(200)* [[ADDRESS_WITH_BOUNDS]], i32 addrspace(200)* [[ADDRESS_WITH_BOUNDS1]])
; HOIST-OPT-NEXT:    [[INC]] = add nuw nsw i32 [[I_06]], 1
; HOIST-OPT-NEXT:    [[CMP:%.*]] = icmp ult i32 [[I_06]], 99
; HOIST-OPT-NEXT:    br i1 [[CMP]], label [[FOR_BODY]], label [[FOR_COND_CLEANUP]]
;
entry:
  %tobool = icmp eq %struct.foo addrspace(200)* %f, null
  %0 = bitcast %struct.foo addrspace(200)* %f to i8 addrspace(200)*
  %dst = getelementptr inbounds %struct.foo, %struct.foo addrspace(200)* %f, i64 0, i32 1
  %1 = bitcast i32 addrspace(200)* %dst to i8 addrspace(200)*
  br label %for.body

for.cond.cleanup:                                 ; preds = %for.inc
  ret void

for.body:                                         ; preds = %entry, %for.inc
  %i.06 = phi i32 [ 0, %entry ], [ %inc, %for.inc ]
  br i1 %tobool, label %for.inc, label %if.then

if.then:                                          ; preds = %for.body
  %2 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %0, i64 4)
  %address.with.bounds = bitcast i8 addrspace(200)* %2 to i32 addrspace(200)*
  %3 = call i8 addrspace(200)* @llvm.cheri.cap.bounds.set.i64(i8 addrspace(200)* nonnull %1, i64 4)
  %address.with.bounds1 = bitcast i8 addrspace(200)* %3 to i32 addrspace(200)*
  call void @call(i32 addrspace(200)* %address.with.bounds, i32 addrspace(200)* %address.with.bounds1)
  br label %for.inc

for.inc:                                          ; preds = %for.body, %if.then
  %inc = add nuw nsw i32 %i.06, 1
  %cmp = icmp ult i32 %i.06, 99
  br i1 %cmp, label %for.body, label %for.cond.cleanup
}
