; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes --force-update
; DO NOT EDIT -- This file was generated from test/CodeGen/CHERI-Generic/Inputs/cheri-address-get-opt.ll
; RUN: opt -S -instcombine -mtriple=aarch64 --relocation-model=pic -target-abi aapcs -mattr=+morello,-c64 %s -o - | FileCheck %s --check-prefix=HYBRID
; RUN: opt -S -instcombine -mtriple=aarch64 --relocation-model=pic -target-abi purecap -mattr=+morello,+c64 %s -o - | FileCheck %s --check-prefix=PURECAP

@a = addrspace(200) global [200 x i32] zeroinitializer, align 4

define i64 @foo() {
; HYBRID-LABEL: define {{[^@]+}}@foo
; HYBRID-SAME: () #[[ATTR0:[0-9]+]] {
; HYBRID-NEXT:  entry:
; HYBRID-NEXT:    ret i64 196
;
; PURECAP-LABEL: define {{[^@]+}}@foo
; PURECAP-SAME: () #[[ATTR0:[0-9]+]] {
; PURECAP-NEXT:  entry:
; PURECAP-NEXT:    ret i64 196
;
entry:
  %0 = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* bitcast (i32 addrspace(200)* getelementptr inbounds ([200 x i32], [200 x i32] addrspace(200)* @a, i64 0, i64 198) to i8 addrspace(200)*))
  %1 = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* bitcast (i32 addrspace(200)* getelementptr inbounds ([200 x i32], [200 x i32] addrspace(200)* @a, i64 0, i64 2) to i8 addrspace(200)*))
  %sub.ptr.sub = sub i64 %0, %1
  %sub.ptr.div = sdiv exact i64 %sub.ptr.sub, 4
  ret i64 %sub.ptr.div
}

declare i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)*)

; Don't fold a subtract of cheri_cap_address_get to cap_diff.
define i64 @bar(i64 %i) {
; HYBRID-LABEL: define {{[^@]+}}@bar
; HYBRID-SAME: (i64 [[I:%.*]]) #[[ATTR0]] {
; HYBRID-NEXT:  entry:
; HYBRID-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [200 x i32], [200 x i32] addrspace(200)* @a, i64 0, i64 [[I]]
; HYBRID-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* bitcast (i32 addrspace(200)* getelementptr inbounds ([200 x i32], [200 x i32] addrspace(200)* @a, i64 0, i64 198) to i8 addrspace(200)*))
; HYBRID-NEXT:    [[TMP1:%.*]] = bitcast i32 addrspace(200)* [[ARRAYIDX]] to i8 addrspace(200)*
; HYBRID-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP1]])
; HYBRID-NEXT:    [[SUB_PTR_SUB:%.*]] = sub i64 [[TMP0]], [[TMP2]]
; HYBRID-NEXT:    [[SUB_PTR_DIV:%.*]] = ashr exact i64 [[SUB_PTR_SUB]], 2
; HYBRID-NEXT:    ret i64 [[SUB_PTR_DIV]]
;
; PURECAP-LABEL: define {{[^@]+}}@bar
; PURECAP-SAME: (i64 [[I:%.*]]) #[[ATTR0]] {
; PURECAP-NEXT:  entry:
; PURECAP-NEXT:    [[ARRAYIDX:%.*]] = getelementptr inbounds [200 x i32], [200 x i32] addrspace(200)* @a, i64 0, i64 [[I]]
; PURECAP-NEXT:    [[TMP0:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* bitcast (i32 addrspace(200)* getelementptr inbounds ([200 x i32], [200 x i32] addrspace(200)* @a, i64 0, i64 198) to i8 addrspace(200)*))
; PURECAP-NEXT:    [[TMP1:%.*]] = bitcast i32 addrspace(200)* [[ARRAYIDX]] to i8 addrspace(200)*
; PURECAP-NEXT:    [[TMP2:%.*]] = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* [[TMP1]])
; PURECAP-NEXT:    [[SUB_PTR_SUB:%.*]] = sub i64 [[TMP0]], [[TMP2]]
; PURECAP-NEXT:    [[SUB_PTR_DIV:%.*]] = ashr exact i64 [[SUB_PTR_SUB]], 2
; PURECAP-NEXT:    ret i64 [[SUB_PTR_DIV]]
;
entry:
  %arrayidx = getelementptr inbounds [200 x i32], [200 x i32] addrspace(200)* @a, i64 0, i64 %i
  %0 = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* bitcast (i32 addrspace(200)* getelementptr inbounds ([200 x i32], [200 x i32] addrspace(200)* @a, i64 0, i64 198) to i8 addrspace(200)*))
  %1 = bitcast i32 addrspace(200)* %arrayidx to i8 addrspace(200)*
  %2 = call i64 @llvm.cheri.cap.address.get.i64(i8 addrspace(200)* %1)
  %sub.ptr.sub = sub i64 %0, %2
  %sub.ptr.div = sdiv exact i64 %sub.ptr.sub, 4
  ret i64 %sub.ptr.div
}
