; NOTE: Assertions have been autogenerated by utils/update_test_checks.py UTC_ARGS: --function-signature --scrub-attributes --force-update
; DO NOT EDIT -- This file was generated from test/CodeGen/CHERI-Generic/Inputs/setoffset-multiple-uses.ll
; RUN: opt -S -instcombine -o - %s | FileCheck %s
; RUN: opt -S -instcombine -o - %s | llc -mtriple=aarch64 --relocation-model=pic -target-abi purecap -mattr=+morello,+c64 -O1 - -o - | %cheri_FileCheck %s --check-prefix ASM

target datalayout = "e-m:e-pf200:128:128:128:64-i8:8:32-i16:16:32-i64:64-i128:128-n32:64-S128-A200-P200-G200"
; Reduced test case for a crash in the new optimization to fold multiple setoffset calls (orignally found when compiling libunwind)

declare i64 @check_fold(i64) addrspace(200)
declare void @check_fold_i8ptr(i8 addrspace(200)*) addrspace(200)
declare i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)*) addrspace(200)
declare i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)*, i64) addrspace(200)

define void @infer_values_from_null_set_offset() addrspace(200) nounwind {
; ASM-LABEL: infer_values_from_null_set_offset:
; ASM:       .Lfunc_begin0:
; ASM-NEXT:  // %bb.0:
; ASM-NEXT:    str c30, [csp, #-16]! // 16-byte Folded Spill
; ASM-NEXT:    mov w0, #57920
; ASM-NEXT:    movk w0, #1, lsl #16
; ASM-NEXT:    bl check_fold
; ASM-NEXT:    ldr c30, [csp], #16 // 16-byte Folded Reload
; ASM-NEXT:    ret c30
; CHECK-LABEL: define {{[^@]+}}@infer_values_from_null_set_offset
; CHECK-SAME: () addrspace(200) [[ATTR1:#.*]] {
; CHECK-NEXT:    [[OFFSET_CHECK:%.*]] = call i64 @check_fold(i64 123456)
; CHECK-NEXT:    ret void
;
  %with_offset = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* null, i64 123456)
  %offset = call i64 @llvm.cheri.cap.offset.get.i64(i8 addrspace(200)* nonnull %with_offset)
  %offset_check = call i64 @check_fold(i64 %offset)
  ret void
}

define void @multiple_uses_big_constant() addrspace(200) nounwind {
; ASM-LABEL: multiple_uses_big_constant:
; ASM:       .Lfunc_begin1:
; ASM-NEXT:  // %bb.0:
; ASM-NEXT:    stp c30, c19, [csp, #-32]! // 32-byte Folded Spill
; ASM-NEXT:    mov w8, #57920
; ASM-NEXT:    mov x0, #0
; ASM-NEXT:    movk w8, #1, lsl #16
; ASM-NEXT:    add c19, c0, x8, uxtx
; ASM-NEXT:    mov c0, c19
; ASM-NEXT:    bl check_fold_i8ptr
; ASM-NEXT:    mov c0, c19
; ASM-NEXT:    bl check_fold_i8ptr
; ASM-NEXT:    mov c0, c19
; ASM-NEXT:    bl check_fold_i8ptr
; ASM-NEXT:    ldp c30, c19, [csp], #32 // 32-byte Folded Reload
; ASM-NEXT:    ret c30
; CHECK-LABEL: define {{[^@]+}}@multiple_uses_big_constant
; CHECK-SAME: () addrspace(200) [[ATTR1]] {
; CHECK-NEXT:    call void @check_fold_i8ptr(i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 123456))
; CHECK-NEXT:    call void @check_fold_i8ptr(i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 123456))
; CHECK-NEXT:    call void @check_fold_i8ptr(i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 123456))
; CHECK-NEXT:    ret void
;
  %with_offset = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* null, i64 123456)
  call void @check_fold_i8ptr(i8 addrspace(200)* %with_offset)
  call void @check_fold_i8ptr(i8 addrspace(200)* %with_offset)
  call void @check_fold_i8ptr(i8 addrspace(200)* %with_offset)
  ret void
}

; Here we should use an immediate cincoffset:
define void @multiple_uses_small_constant() addrspace(200) nounwind {
; ASM-LABEL: multiple_uses_small_constant:
; ASM:       .Lfunc_begin2:
; ASM-NEXT:  // %bb.0:
; ASM-NEXT:    stp c30, c19, [csp, #-32]! // 32-byte Folded Spill
; ASM-NEXT:    mov x0, #0
; ASM-NEXT:    add c19, c0, #123 // =123
; ASM-NEXT:    mov c0, c19
; ASM-NEXT:    bl check_fold_i8ptr
; ASM-NEXT:    mov c0, c19
; ASM-NEXT:    bl check_fold_i8ptr
; ASM-NEXT:    mov c0, c19
; ASM-NEXT:    bl check_fold_i8ptr
; ASM-NEXT:    ldp c30, c19, [csp], #32 // 32-byte Folded Reload
; ASM-NEXT:    ret c30
; CHECK-LABEL: define {{[^@]+}}@multiple_uses_small_constant
; CHECK-SAME: () addrspace(200) [[ATTR1]] {
; CHECK-NEXT:    call void @check_fold_i8ptr(i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 123))
; CHECK-NEXT:    call void @check_fold_i8ptr(i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 123))
; CHECK-NEXT:    call void @check_fold_i8ptr(i8 addrspace(200)* getelementptr (i8, i8 addrspace(200)* null, i64 123))
; CHECK-NEXT:    ret void
;
  %with_offset = call i8 addrspace(200)* @llvm.cheri.cap.offset.set.i64(i8 addrspace(200)* null, i64 123)
  call void @check_fold_i8ptr(i8 addrspace(200)* %with_offset)
  call void @check_fold_i8ptr(i8 addrspace(200)* %with_offset)
  call void @check_fold_i8ptr(i8 addrspace(200)* %with_offset)
  ret void
}
